---
layout: post
title:  "Централизованное логирование"
date:   2023-01-20 15:21:14 +0000
categories: howto
---

Представим, что вы — системный инженер в небольшой IT-компании. У компании десять серверов; некоторые обслуживают бухгалтерию, некоторые используются для разработки и тестирования ПО. Вам нужно обеспечивать стабильную работу серверов, анализировать их работу, а в случае сбоев — быстро находить причину сбоя.

В поиске причин вам помогут логи, а системы централизованного логирования позволят собрать логи со всех серверов в одно место и значительно сократят время поиска.

В этом занятии мы освежим то, что уже знаем о логах, а также разберемся, как их аггрегировать и анализировать. Если мы качественно настроим централизованное логирование, поиск нужных нам записей на 10 и на 100 серверах будет занимать одинаковое время.

### Что такое логи?

Почти все приложения, которые мы запускаем, пишут логи. Логи — это записи о событиях, возникающих во время работы программы.

Логи в процессе функционирования программы пишутся автоматически и сохраняются в файлы.

Работая с логами, мы обычно говорим про анализ произошедших событий. Изучая логи, мы можем понять, к примеру:

- Когда и почему возникали системные ошибки (ошибки файловой системы, ошибки выделения памяти, проблемы с сетевыми устройствами и драйверами)
- Когда и кто подключался к серверам — и какие операции выполнял
- Какие запросы идут на наш HTTP-сервер и с каких адресов
- Какие запросы в базу данных выполняются медленнее всего
- Почему приложение не запускается на заданных настройках

Проанализировав события и частоту их возникновения за определенный период, мы можем оценить, является ли наличие этих событий нормой, и если нет - принять решения по исправлению ситуации.

### Где их искать?

Системные логи Windows хранятся в `Windows\system32\config`. Их можно просматривать через приложение "Event Viewer" (вызов через командную строку: `eventvwr.msc`). Логи приложений могут храниться в директории приложения или в `AppData\Local` пользователя — информацию можно найти в документации конкретного приложения.

В Unix-like операционных системах (например, MacOS и семейство Linux) логи текстовые. Для работы с ними достаточно терминала. Как правило, логи стоит искать в `/var/log`. Там же создаются директории для логов приложений.

Например, можем найти там логи авторизации в систему:

{% highlight sh %}
tail /var/log/auth.log

# =>
Jan 23 11:49:37 web-01 systemd-logind[509]: Removed session 1894068.
Jan 23 11:49:42 web-01 sshd[2955520]: Invalid user alex from 124.42.78.202 port 44442
Jan 23 11:49:42 web-01 sshd[2955520]: pam_unix(sshd:auth): check pass; user unknown
Jan 23 11:49:42 web-01 sshd[2955520]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=159.65.34.202
Jan 23 11:49:43 web-01 sshd[2955520]: Failed password for invalid user alex from 124.42.78.202 port 44442 ssh2
Jan 23 11:49:45 web-01 sshd[2955520]: Received disconnect from 124.42.78.202 port 44442:11: Bye Bye [preauth]
Jan 23 11:49:45 web-01 sshd[2955520]: Disconnected from invalid user alex 124.42.78.202 port 44442 [preauth]
Jan 23 11:50:00 web-01 sshd[2955522]: Accepted publickey for ubuntu from 124.42.78.202 port 47368 ssh2: RSA SHA256:#
Jan 23 11:50:00 web-01 sshd[2955522]: pam_unix(sshd:session): session opened for user ubuntu by (uid=0)
Jan 23 11:50:00 web-01 systemd-logind[509]: New session 1894069 of user ubuntu.
{% endhighlight %}

Большую часть системных логов Linux, связанных с функционированием сервисов и приложений, мы найдем в `/var/log/syslog` или в `/var/log/messages`:

{% highlight sh %}
tail /var/log/syslog

# =>
Jan 23 12:07:53 web-01 systemd[1]: Started Session 1905779 of user ubuntu.
Jan 23 12:07:53 web-01 ntpd[545]: Soliciting pool server 91.209.94.10
Jan 23 12:07:54 web-01 ntpd[545]: Soliciting pool server 188.225.9.167
Jan 23 12:07:59 web-01 ntpd[545]: Soliciting pool server 85.254.217.3
Jan 23 12:08:10 web-01 systemd[1]: Started Session 1905780 of user ubuntu.

{% endhighlight %}

### Как их анализировать?

Возьмем простой пример, для чего нам эти логи могут пригодиться. Обратимся к `/var/log/auth.log`, записи которого мы просматривали ранее.

Далее воспользуемся текстовым поиском, чтобы найти записи, которые нас интересуют. Поищем записи с `Failed password`:

{% highlight sh %}
tail -n 1000 /var/log/auth.log | grep "Failed password"

# =>
Jan 23 11:52:53 web-01 sshd[2957865]: Failed password for invalid user user from 159.65.34.202 port 42674 ssh2
Jan 23 11:54:27 web-01 sshd[2958758]: Failed password for invalid user nagios from 159.65.34.202 port 55907 ssh2
Jan 23 11:56:05 web-01 sshd[2960142]: Failed password for invalid user steam from 159.65.34.202 port 40907 ssh2
Jan 23 11:57:47 web-01 sshd[2961552]: Failed password for invalid user frappe from 159.65.34.202 port 54139 ssh2
Jan 23 11:59:24 web-01 sshd[2962650]: Failed password for invalid user developer from 159.65.34.202 port 39139 ssh2
{% endhighlight %}

Проанализировав выдачу поиска, мы делаем вывод, что кто-то пытается подобрать пользователя для подключения к серверу. Следовательно, стоит уделить внимание сетевой безопасности сервера.

### Сбор логов

Копая логи на серверах по отдельности, можно найти много интересного. Но есть аспекты, которые становятся критичными при масштабировании:

- Нужно знать, где искать (и в разных операционных системах это могут быть разные места)
- Логи на серверах не хранятся слишком долго, чтобы не занимать ценное дисковое пространство; горизонт поиска ограничен сроком [ротации логов](https://www.oslogic.ru/knowledge/431/rotatsiya-logov-logrotate/)
- Гигабайтные файлы логов высоконагруженных приложений сложно анализировать текстовыми фильтрами
- Нет целостной картины происходящего на серверах; сложно связать взаимозависимые события на разных машинах

Чтобы решить вышеописанные проблемы, используется централизованное логирование.

На каждом сервере ставится приложение-**агент** (он же shipper, он же listener), которое сканирует новые строки в указанных ему лог-файлах. Агент передает собранные логи по сети к аггрегатору логов. **Аггрегатор** принимает логи, обрабатывает их, структурирует и пишет в базу. **Визуализатор** отправляет запросы к аггрегатору, чтобы достать из базы нужные логи и показать их в удобном интерфейсе.

![Централизованное логирование](https://galex-do.github.io/pages/assets/images/centralized_logging.png "Централизованное логирование")

Это обобщенная концепция, но в целом она описывает, как происходит сбор и анализ логов в распределенных системах. Похожим образом агент собирает логи с контейнеров Docker и с подов в Kubernetes.

Каждая запись тегируется агентом. С помощью тегов мы можем отфильтровать получаемые из базы записи и получить, к примеру, логи авторизации всех серверов, записанные в прошедшем месяце. Аггрегатор индексирует данные по тегам — в результате физически такой запрос выполняется значительно быстрее, чем если бы мы собрали все лог-файлы в один и попытались отфильтровать данные текстовым поиском.

### Решения

Рассмотрим несколько решений централизованного логирования, взвесим их плюсы и минусы и попробуем настроить логирование с помощью одного из них.

[**ELK-стек**](https://www.elastic.co/elastic-stack/) расшифровывается как Elasticsearch + Logstash + Kibana. Все три продукта, а также многочисленные агенты Beats поддерживает и развивает компания Elasticsearch. У всех продуктов Elasticsearch единая линейка версионирования — зная версию Elasticsearch, вы можете быть уверены, что найдете Logstash, Kibana и Beats той же версии, и они будут полностью совместимы.

ELK весьма популярен как облачное решение, и доступен как интегрированная платформа для сбора логов (Amazon EC2, Elastic Cloud в Google Cloud Platform)

Агентами в случае ELK выступают Beats (Filebeat, Metricbeat, Auditbeat, etc). В том числе, у Elastic есть Winlogbeat для сбора Event-логов Windows.

Если сведем обзор по решениям в табличку, получим примерно такое разделение отвественностей между компонентами

| Стек    | Shipper  | Collector | Database & Search | Visualizer |
|---------|----------|-----------|-------------------|------------|
| ELK     | Beats    | Logstash  | Elasticsearch     | Kibana     |
| EFK     | Fluentd  | Fluentd   | Elasticsearch     | Kibana     |
| Graylog | Fluentd  | Fluentd   | Elasticsearch     | Graylog    |
| Loki    | Promtail | Loki      | Loki              | Grafana    |

#### EFK

#### Loki + Grafana



### Настроим сбор логов

todo

### В итоге

Итак, на занятии мы:

* Вспомнили, зачем нужны логи и где они хранятся
* Разобрались с концепцией централизованного логирования и что для него используют
* Попробовали настроить логирование с помощью Grafana и Loki
* Познакомились с языком запросов LogQL

Знание, как организовать централизованное логирование, позволит вам упростить контроль событий в больших кластерах серверов, а также контейнерных решениях, таких как Docker и Kubernetes.
