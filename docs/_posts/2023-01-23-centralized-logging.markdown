---
layout: post
title:  "Централизованное логирование"
date:   2023-01-20 15:21:14 +0000
categories: howto
---

Представим, что вы — системный инженер в небольшой IT-компании. У компании десять серверов; некоторые обслуживают бухгалтерию, некоторые используются для разработки и тестирования ПО. Вам нужно обеспечивать стабильную работу серверов, анализировать их работу, а в случае сбоев — быстро находить причину сбоя.

В поиске причин вам помогут логи, а системы централизованного логирования позволят собрать логи со всех серверов в одно место и значительно сократят время поиска.

В этом занятии мы освежим то, что уже знаем о логах, а также разберемся, как их аггрегировать и анализировать. Если мы качественно настроим централизованное логирование, поиск нужных нам записей на 10 и на 100 серверах будет занимать одинаковое время.

### Что такое логи?

Почти все приложения, которые мы запускаем, пишут логи. Логи — это записи о событиях, возникающих во время работы программы.

Логи в процессе функционирования программы пишутся автоматически и сохраняются в файлы.

Работая с логами, мы обычно говорим про анализ произошедших событий. Изучая логи, мы можем понять, к примеру:

- Когда и почему возникали системные ошибки (ошибки файловой системы, ошибки выделения памяти, проблемы с сетевыми устройствами и драйверами)
- Когда и кто подключался к серверам — и какие операции выполнял
- Какие запросы идут на наш HTTP-сервер и с каких адресов
- Какие запросы в базу данных выполняются медленнее всего
- Почему приложение не запускается на заданных настройках

Проанализировав события и частоту их возникновения за определенный период, мы можем оценить, является ли наличие этих событий нормой, и если нет - принять решения по исправлению ситуации.

### Где их искать?

Системные логи Windows хранятся в `Windows\system32\config`. Их можно просматривать через приложение "Event Viewer" (вызов через командную строку: `eventvwr.msc`). Логи приложений могут храниться в директории приложения или в `AppData\Local` пользователя — информацию можно найти в документации конкретного приложения.

В Unix-like операционных системах (например, MacOS и семейство Linux) логи текстовые. Для работы с ними достаточно терминала. Как правило, логи стоит искать в `/var/log`. Там же создаются директории для логов приложений.

Например, можем найти там логи авторизации в систему:

{% highlight sh %}
tail /var/log/auth.log

# =>
Jan 23 11:49:37 web-01 systemd-logind[509]: Removed session 1894068.
Jan 23 11:49:42 web-01 sshd[2955520]: Invalid user alex from 124.42.78.202 port 44442
Jan 23 11:49:42 web-01 sshd[2955520]: pam_unix(sshd:auth): check pass; user unknown
Jan 23 11:49:42 web-01 sshd[2955520]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=159.65.34.202
Jan 23 11:49:43 web-01 sshd[2955520]: Failed password for invalid user alex from 124.42.78.202 port 44442 ssh2
Jan 23 11:49:45 web-01 sshd[2955520]: Received disconnect from 124.42.78.202 port 44442:11: Bye Bye [preauth]
Jan 23 11:49:45 web-01 sshd[2955520]: Disconnected from invalid user alex 124.42.78.202 port 44442 [preauth]
Jan 23 11:50:00 web-01 sshd[2955522]: Accepted publickey for ubuntu from 124.42.78.202 port 47368 ssh2: RSA SHA256:#
Jan 23 11:50:00 web-01 sshd[2955522]: pam_unix(sshd:session): session opened for user ubuntu by (uid=0)
Jan 23 11:50:00 web-01 systemd-logind[509]: New session 1894069 of user ubuntu.
{% endhighlight %}

Большую часть системных логов Linux, связанных с функционированием сервисов и приложений, мы найдем в `/var/log/syslog` или в `/var/log/messages`:

{% highlight sh %}
tail /var/log/syslog

# =>
Jan 23 12:07:53 web-01 systemd[1]: Started Session 1905779 of user ubuntu.
Jan 23 12:07:53 web-01 ntpd[545]: Soliciting pool server 91.209.94.10
Jan 23 12:07:54 web-01 ntpd[545]: Soliciting pool server 188.225.9.167
Jan 23 12:07:59 web-01 ntpd[545]: Soliciting pool server 85.254.217.3
Jan 23 12:08:10 web-01 systemd[1]: Started Session 1905780 of user ubuntu.

{% endhighlight %}

### Как их анализировать?

Возьмем простой пример, для чего нам эти логи могут пригодиться. Обратимся к `/var/log/auth.log`, записи которого мы просматривали ранее.

Далее воспользуемся текстовым поиском, чтобы найти записи, которые нас интересуют. Поищем записи с `Failed password`:

{% highlight sh %}
tail -n 1000 /var/log/auth.log | grep "Failed password"

# =>
Jan 23 11:52:53 web-01 sshd[2957865]: Failed password for invalid user user from 159.65.34.202 port 42674 ssh2
Jan 23 11:54:27 web-01 sshd[2958758]: Failed password for invalid user nagios from 159.65.34.202 port 55907 ssh2
Jan 23 11:56:05 web-01 sshd[2960142]: Failed password for invalid user steam from 159.65.34.202 port 40907 ssh2
Jan 23 11:57:47 web-01 sshd[2961552]: Failed password for invalid user frappe from 159.65.34.202 port 54139 ssh2
Jan 23 11:59:24 web-01 sshd[2962650]: Failed password for invalid user developer from 159.65.34.202 port 39139 ssh2
{% endhighlight %}

Проанализировав выдачу поиска, мы делаем вывод, что кто-то пытается подобрать пользователя для подключения к серверу. Следовательно, стоит уделить внимание сетевой безопасности.

### Централизованный сбор логов

Копая логи на серверах по отдельности, можно найти много интересного. Но чем больше парк серверов или нагрузка на него, тем громче начинают говорить о себе проблемы:

- Нужно знать, где искать нужные логи (и в разных операционных системах это бывают разные места)
- Логи на серверах не хранятся слишком долго, чтобы не занимать ценное дисковое пространство; горизонт поиска ограничен сроком [ротации логов](https://www.oslogic.ru/knowledge/431/rotatsiya-logov-logrotate/)
- Гигабайтные файлы логов высоконагруженных приложений сложно анализировать текстовыми фильтрами
- Нет целостной картины происходящего на серверах; сложно связать взаимозависимые события на разных машинах

Бонусом к этому, нам было бы полезно видеть динамику записи логов, чтобы отследить пики нагрузки и подозрительные активности.

Чтобы решить вышеописанные проблемы, используется **централизованное логирование**. Его идея в том, что мы собираем логи со всех наших серверов в одно место, где можем работать с ними, используя расширенные возможности поисковых движков и инструментов визуализации.

#### Как это работает?

На каждом сервере ставится приложение-**агент** (он же shipper, он же exporter), которое сканирует новые строки в указанных ему лог-файлах. Агент передает собранные логи по сети к аггрегатору логов. **Аггрегатор** принимает логи, обрабатывает их, структурирует и пишет в базу. **Визуализатор** отправляет запросы к аггрегатору, чтобы достать из базы нужные логи и показать их в удобном интерфейсе.

![Централизованное логирование](https://galex-do.github.io/pages/assets/images/centralized_logging.png "Централизованное логирование")

Это обобщенная концепция, но в целом она описывает, как происходит сбор и анализ логов в распределенных системах. Похожим образом агент собирает логи с контейнеров Docker и с подов в Kubernetes.

Агент тегирует каждую запись лога. С помощью тегов мы можем отфильтровать получаемые из базы записи и получить, к примеру, логи авторизации всех серверов, записанные в прошедшем месяце. Аггрегатор индексирует данные по тегам — в результате физически такой запрос выполняется значительно быстрее, чем если бы мы собрали все лог-файлы в один и попытались отфильтровать данные текстовым поиском.

#### Решения

Поскольку решения централизованного логирования всегда состоят из нескольких компонентов (агент, аггрегатор, визуализатор), описывая их, мы говорим о понятии стека. Стек — несколько программных продуктов, решающих в совокупности задачу сбора, упорядочивания и анализа логов. Рассмотрим наиболее часто встречающиеся стеки, затем попробуем настроить один из них.

[**ELK-стек**](https://www.elastic.co/elastic-stack/) расшифровывается как Elasticsearch + Logstash + Kibana. Все три продукта, а также многочисленные агенты Beats поддерживает и развивает компания Elasticsearch. У всех продуктов Elasticsearch единая линейка версионирования — зная версию Elasticsearch, вы можете быть уверены, что найдете Logstash, Kibana и Beats той же версии, и они будут полностью совместимы.

Также Elasticsearch поддерживает полностью бесплатную OSS-версию стека (с урезанной функциональностью, но вполне подходящую для решения базовых задач логирования).

ELK весьма популярен как облачное решение, и доступен как интегрированная платформа для сбора логов (Amazon EC2, Elastic Cloud в Google Cloud Platform, Yandex Managed Elasticsearch). ELK можно развернуть на своих сравнительно небольших мощностях; также ELK хорошо умеет масштабироваться горизонтально и годится для логирования крупных высоконагруженных проектов.

Агентами, собирающими логи на местах, в случае ELK выступают Beats (Filebeat, Metricbeat, Auditbeat, Winlogbeat для сбора Event-логов Windows, etc). Logstash принимает "сырые" логи от Beats и с других направлений, фильтрует их, индексирует и складывает в Elasticsearch. Elasticsearch предоставляет базу данных и поисковой движок к ней. А Kibana предоставляет Web-интерфейс, позволяющий визуализировать данные, хранимые в Elasticsearch  

![ELK](https://galex-do.github.io/pages/assets/images/logging_blek.png "ELK")

**EFK-стек** расшифровывается как Elasticsearch + Fluentd + Kibana. [Fluentd](https://docs.fluentbit.io/manual/about/fluentd-and-fluent-bit) заменяет собой связку Beats + Logstash из предыдущей схемы.

Fluentd лучше адаптирован к контейнерной инфраструктуре и чаще применяется в инфраструктуре на базе Docker и Kubernetes. В семейство Fluentd также входит легковесный Fluent-bit, потребляющий значительно меньше ресурсов, чем аналогичное решение на базе Beats + Logstash.

![EFK](https://galex-do.github.io/pages/assets/images/logging_fek.png "EFK")

**PLG-стек** расшифровывается как Prometheus + Loki + Grafana, но в контексте централизованного логирования нас интересуют последние два. Стек продуктов с открытым исходным кодом развивает и поддерживает команда [Grafana Labs](https://github.com/grafana). PLG-стек преимущественно написан на языке Go, что делает его компоненты более быстрыми и менее ресурсозатратными, чем компоненты ELK-стека.

Агентом в PLG-стеке является Promtail

PLG удобен на небольших и средних проектах. Loki умеет экспортировать логи в объектное хранилище для длительного хранения, что позволяет сэкономить на хранении данных, особенно при использовании облачных платформ.

![PLG](https://galex-do.github.io/pages/assets/images/logging_plg.png "PLG")

Если сведем обзор по решениям в табличку, получим примерно такое разделение отвественностей между компонентами

| Стек    | Shipper  | Collector | Database & Search | Visualizer |
|---------|----------|-----------|-------------------|------------|
| ELK     | Beats    | Logstash  | Elasticsearch     | Kibana     |
| EFK     | Fluentd  | Fluentd   | Elasticsearch     | Kibana     |
| Loki    | Promtail | Loki      | Loki              | Grafana    |

И это только самые частые комбинации. В реальности компоненты стеков постоянно развиваются и становятся взаимозаменяемыми. Например, мы [можем использовать Grafana](https://grafana.com/docs/grafana/latest/datasources/elasticsearch/) вместо Kibana, чтобы визуализировать данные Elasticsearch. При выборе конечного решения стоит учитывать:

- Запросы к сбору и обработке логов; наличие соответствующих плагинов у компонентов стека
- Объем генерируемых логов
- Знакомство с решением и удобство пользования

### Настроим сбор логов

todo

### В итоге

Итак, на занятии мы:

* Вспомнили, зачем нужны логи и где они хранятся
* Разобрались с концепцией централизованного логирования и что для него используют
* Попробовали настроить логирование с помощью Grafana и Loki
* Познакомились с языком запросов LogQL

Знание, как организовать централизованное логирование, позволит вам упростить контроль событий в больших кластерах серверов, а также контейнерных решениях, таких как Docker и Kubernetes.

### Ссылки

* https://signoz.io/blog/fluentd-vs-logstash/
* https://habr.com/ru/company/southbridge/blog/510822/
* https://habr.com/ru/company/badoo/blog/507718/
