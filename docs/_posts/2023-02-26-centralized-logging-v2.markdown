---
layout: post
title:  "Централизованное логирование V2"
date:   2023-02-26 12:00:00 +0300
categories: howto
---

Представим, что вы — системный инженер в небольшой IT-компании. У компании десять серверов; некоторые обслуживают бухгалтерию, некоторые используются для разработки и тестирования ПО. Для доступа к ресурсам снаружи закрытой сети используется прокси-сервер.

![Исходная схема сети](https://galex-do.github.io/pages/assets/images/logging_scheme1.png "Исходная схема сети")

Вы обеспечиваете стабильную работу серверов, анализируете их работу, а в случае сбоев — должны быстро находить причину сбоя. В поиске причин вам помогут логи, а системы централизованного логирования позволят собрать логи со всех серверов в одно место и сократят время поиска.

В этом занятии мы освежим то, что уже знаем о логах, а также разберемся, как их агрегировать и анализировать. Если мы качественно настроим централизованное логирование, поиск нужных нам записей на 10 и на 100 серверах будет занимать одинаковое время.

### Что такое логи?

Почти все приложения, которые мы запускаем, автоматически пишут логи. Логи — это записи о событиях, возникающих во время работы программы.

![Логи](https://galex-do.github.io/pages/assets/images/logging_ss1.png "Логи")

Работая с логами, мы обычно говорим про анализ произошедших событий. Изучая логи, мы понимаем:

- Когда и почему возникали системные ошибки — ошибки файловой системы, ошибки выделения памяти, проблемы с сетевыми устройствами и драйверами
- Когда и кто подключался к серверам — и какие операции выполнял
- Какие запросы идут на наш HTTP-сервер и с каких адресов
- Какие запросы в базу данных выполняются медленнее всего
- Почему приложение не запускается на заданных настройках

Проанализировав события и частоту их возникновения за определенный период, мы оцениваем, является ли наличие этих событий нормой, и если нет — принимаем решение по исправлению ситуации.

### Проблемы поиска логов

Поиск логов на отдельных серверах в целом является решаемой задачей. Главная сложность возникает, когда в инфраструктуре появляется несколько серверов, параллельно решающих одну и ту же задачу.

Возьмем для примера схему, описанную в начале, и представим, что для бесперебойного доступа к нашей сети используется три прокси вместо одного, и балансировщик перед ними.

![Продвинутая схема сети](https://galex-do.github.io/pages/assets/images/logging_scheme2.png "Продвинутая схема сети")

Теперь у нас есть три условно одинаковых сервера, между которыми балансировщик равномерно распределяет все поступающие к нему запросы. Поймав ошибку на уровне прокси, мы получим только одну запись лога — на одном из трёх серверов. Чтобы найти её, нам в худшем случае придется посетить все три сервера.

Альтернативное решение — непрерывно выгружать логи со всех трех серверов в одну точку и анализировать события там. Что, в итоге, подводит нас к концепции централизованного логирования.

### Централизованный сбор логов

При централизованном логировании мы собираем логи со всех наших серверов в единую базу, где можем работать с ними, абстрагируясь от физических особенностей инфаструктуры. При наличии централизованного логирования нам не важно, сколько машин выполняет задачи прокси — **все** события, связанные с работой прокси, мы увидим на сервере с логами.

Помимо этого, централизованный сбор логов имеет следующие плюсы:

- Абстрагирование от того, где на серверах хранятся логи. Достаточно один раз настроить на сервере, откуда их собирать.
- Не нужно хранить много логов на самих серверах с приложениями — вся история будет храниться в базе системы логирования.
- Решения централизованного логирования часто предоставляют эффективные поисковые движки для анализа логов, а также инструменты визуализации, позволяющие отслеживать пики нагрузок и подозрительные активности.
- Появляется целостная картина событий на уровне инфраструктуры. Мы можем отследить, как запрос прошел через прокси, был обработан приложением, и как приложение отправило запрос к базе данных.

#### Как это работает?

На каждом сервере ставится приложение-**агент**, которое собирает записи логов из указанных ему источников. Получив новые записи, агент передает их агрегатору логов.

**Агрегатор** принимает, фильтрует и обрабатывает записи. Агрегатор умеет анализировать содержимое записей и на основе полученной информации что-нибудь с ними делать — например, отфильтровывать ненужные, или помечать их дополнительными тегами. После обработки агрегатор сохраняет отфильтрованные и дополненные записи в базу.

**Визуализатор** отправляет запросы к базе, чтобы достать нужные логи и показать их в удобном интерфейсе.

![Централизованное логирование](https://galex-do.github.io/pages/assets/images/centralized_logging.png "Централизованное логирование")

Источниками логов для агента могут выступать файлы, журналы, другие агенты — как правило, агент поставляется с [набором плагинов](https://www.elastic.co/guide/en/beats/filebeat/current/configuration-filebeat-options.html), каждый из которых реализует конкретную механику сбора логов.

#### Анализ логов в централизованной системе

Агент помечает каждую запись лога тегами. Агрегатор при обработке записей тоже может дописывать в них какую-то информацию — чтобы в дальнейшем записи было проще структурировать.

Данные в хранилище логов в той или иной степени индексируются по тегам. В результате физически запросы по тегам выполняются значительно быстрее, чем если бы мы собрали все лог-файлы в один и попытались отфильтровать данные текстовым поиском.

Для примера скажем, что агент собирает все возможные системные логи со всех серверов, помечает их тегом `host` и транслирует агрегатору. Агрегатор фильтрует получаемые записи и сохраняет в базу только те, которые относятся к логам авторизации и содержат строку `Failed password`. При этом он помечает такие события тегом `job` со значением `auth`

В визуализаторе мы сможем использовать этот тег, чтобы найти соответствующие записи в базе за интересующий нас промежуток времени.

[![Grafana explore](https://galex-do.github.io/pages/assets/images/grafana_explore_auth.png "Grafana explore")](https://galex-do.github.io/pages/assets/images/grafana_explore_auth.png)

На графике мы видим динамику таких событий на временной шкале — для всех серверов, с которых мы собираем логи. В списке ниже можно увидеть сами записи. Метка `node-1` в строке записи это и есть тег `host`, присвоенный агентом. Таким образом мы сразу видим, где именно произошло событие.

Чтобы применить эту логику к нашей схеме с тремя прокси, достаточно сказать лог-агенту на каждом из них, чтобы он собирал логи сервиса прокси и помечал их дополнительным тегом `proxy`. Тогда, отфильтровав в визуализаторе записи по тегу `proxy`, мы получим все события с трех серверов.

### В итоге

Итак, на занятии мы:

1. Вспомнили, зачем нужны логи и где они хранятся
2. Разобрались с концепцией централизованного логирования и зачем оно нужно:
    * Собираем логи в единую базу
    * Используем удобные инструменты поиска
    * Видим картину логов в целом и можем связать события на разных серверах
    * Видим динамику событий в логах и отслеживаем аномалии
3. Познакомились с популярными решениями и инструментами централизованного логирования:
    * ELK, если хотим легко и быстро искать по огромному количеству логов, готовы немного покопаться и не стесняемся в средствах
    * Loki + Grafana, если нужно быстро поднять и не тратить на поддержку много ресурсов
    * Fluentd/Fluent-bit, если хотим много плагинов для парсинга логов или думаем о сборе логов в контейнерной инфраструктуре
    * Другие комбинации, если хотим взять сильные стороны из разных решений
4. Настроили централизованное логирование с помощью Grafana и Loki
5. Познакомились с языком запросов LogQL

Знание о том, как организовать централизованное логирование, позволит вам упростить контроль событий в больших кластерах серверов, а также контейнерной инфраструктуре, такой как Docker и Kubernetes.

### Ссылки

* [Откуда Logstash может собирать логи](https://www.elastic.co/guide/en/logstash/current/input-plugins.html)
* [Обзор агентов сбора логов и сравнение с Logstash](https://dev.to/max_kray/top-5-open-source-log-shippers-alternatives-to-logstash-in-2022-5f24)
